## 11/19/2018
######################################################################
# Load packages, clear workspace
######################################################################
rm(list = ls())             #clear workspace
library(foreach)            #for looping
library(data.table)         #for data manipulation
library(Matrix)             #fast matrix calcs
library(ggplot2)            #for pretty plots
library(sandwich)           #for variance-covariance estimation
library(xtable)             #for latex tables
library(boot)               #for bootstrapping
library(mvtnorm)            #for MVN stuff
options(scipen = 999)       #forces R to use normal numbers instead of scientific notation
######################################################################
# Generate random data and simulate
######################################################################
## ECON675: ASSIGNMENT 5
## Q2: WEAK INSTRUMENTS SIMULATIONS
## Anirudh Yadav
## 11/19/2018
######################################################################
# Load packages, clear workspace
######################################################################
rm(list = ls())             #clear workspace
library(foreach)            #for looping
library(data.table)         #for data manipulation
library(Matrix)             #fast matrix calcs
library(ggplot2)            #for pretty plots
library(sandwich)           #for variance-covariance estimation
library(xtable)             #for latex tables
library(boot)               #for bootstrapping
library(mvtnorm)            #for MVN stuff
options(scipen = 999)       #forces R to use normal numbers instead of scientific notation
######################################################################
# Generate random data and simulate
######################################################################
N     = 200
M     = 5000
SIGMA = matrix(c(1,0,0,0,1,0.99,0,0.99,1),3,3)
SIGMA
## ECON675: ASSIGNMENT 5
## Q2: WEAK INSTRUMENTS SIMULATIONS
## Anirudh Yadav
## 11/19/2018
######################################################################
# Load packages, clear workspace
######################################################################
rm(list = ls())             #clear workspace
library(foreach)            #for looping
library(data.table)         #for data manipulation
library(Matrix)             #fast matrix calcs
library(ggplot2)            #for pretty plots
library(sandwich)           #for variance-covariance estimation
library(xtable)             #for latex tables
library(boot)               #for bootstrapping
library(mvtnorm)            #for MVN stuff
options(scipen = 999)       #forces R to use normal numbers instead of scientific notation
######################################################################
# Generate random data and simulate
######################################################################
N     = 200
M     = 5000
SIGMA = matrix(c(1,0,0,0,1,0.99,0,0.99,1),3,3)
set.seed(1234)
# Generate covariates
W     = replicate(M,rmvnorm(N, mean = c(0,0,0), sigma = SIGMA, method="chol"))
dim(W)
# Generate X
gamma.vec = sqrt(1/N)*sqrt(c(0,0.25,9,99))
# Generate X
gamma.vec = sqrt((1/N)*c(0,0.25,9,99))
# Get Y (assuming that beta=0, Y=U)
Y     = W[,2,]
X         = sapply(1:length(gamma.vec),function(i) gamma.vec[i]*W[,1,]+W[,3,])
dim(X)
dim(W[,1,])
dim(W[,1,]+W[,3,])
X         = lapply(1:length(gamma.vec),function(i) gamma.vec[i]*W[,1,]+W[,3,])
View(X)
gamma.vec[1]*W[1,1,1]+W[1,3,1]
gamma.vec[4]*W[1,1,1]+W[1,3,1]
View(X)
dim(X[[1]])
dim(X[[1]][,1])
?dim
nrow(X[[1]][,1])
typeof(X[[1]][,1])
X[[1]][,1]
dim(Y)
lm(Y[,1]~X[[1]][,1])
ans = lm(Y[,1]~X[[1]][,1])
summary(ans)
ans = lm(Y[,1]~X[[1]][,1]-1)
summary(ans)
View(ans)
summary(ans)$coefficients
ans$coefficients
ans$coefficients[1]
# OLS point estimator
ols.beta = sapply(1:M, function(i) lm(Y[,i]~X[[1]][,i]-1)$coefficients)
# OLS point estimator
ols.beta = sapply(1:M, function(i) lm(Y[,i]~X[[1]][,i]-1)$coefficients)
?foreach
mean(ols.beta)
# OLS point estimator
ols.beta = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) lm(Y[,i]~X[[j]][,i]-1)$coefficients)
View(ols.beta)
ols.big = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) lm(Y[,i]~X[[j]][,i]-1))
View(ols.big)
?ivreg
install.packages(AER)
install.packages('AER')
ivreg(Y[,1]~X[[1]][,1]-1|W[,1,1])
library(AER)                #for IV regressions
ivreg(Y[,1]~X[[1]][,1]-1|W[,1,1])
ans=ivreg(Y[,1]~X[[1]][,1]-1|W[,1,1])
View(ans)
View(ols.big)
ols.big[[1]][[1]]
View(ols.beta)
ols.big[[1]]
ols_res <- data.table(tidy(lm(Y[,1]~X[[1]][,1])))
View(ols.big)
# Run OLS for each gamma and each simulation
ols.big = foreach(j=1:length(gamma.vec)) %do%
lapply(1:M, function(i) lm(Y[,i]~X[[j]][,i]-1))
View(ols.big)
View(ols.big)
View(ols.beta)
View(ols.big)
ols.big[[1]][[1]]
ols.big[[1]][[1]]$coefficients
ols.big[[1]][[2]]$coefficients
ols.beta.mean = sapply(1:M, function(i) ols.big[[1]][[i]]$coefficients)
# Extract point estimates, standard errors
ols.beta = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) ols.big[[j]][[i]]$coefficients)
View(ols.beta)
coef(summary(ols.big[[1]][[1]]))[, "Std. Error"]
View(ols.big)
ols.se   = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) summary(ols.big[[j]][[i]])[,"Std. Error"])
summary(ols.big[[1]][[1]])[,"Std. Error"]
ols.se   = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) coef(summary(ols.big[[j]][[i]]))[,"Std. Error"])
View(ols.se)
ols.beta/ols.se
ols.beta[[1]]/ols.se[[1]]
ols.t    = sapply(j=1:length(gamma.vec),ols.beta[[j]]/ols.se[[j]])
ols.t    = sapply(j=1:length(gamma.vec),function(j) ols.beta[[j]]/ols.se[[j]])
ols.t    = sapply(1:length(gamma.vec),function(j) ols.beta[[j]]/ols.se[[j]])
View(ols.t)
ols.reg  = ifelse(ols.t>1.96,1,0)
View(ols.reg)
ols.rej  = ifelse(ols.t>1.96,1,0)
rm(ols.reg)
View(ols.rej)
summary(ols.beta[[1]])
seq(0, 1, 0.25)
quantile(ols.beta[[1]], probs = c(0.1, 0.5 ,0.9))
cbind(mean(ols.beta[[1]]),quantile(ols.beta[[1]], probs = c(0.1, 0.5 ,0.9)))
c(mean(ols.beta[[1]]),quantile(ols.beta[[1]], probs = c(0.1, 0.5 ,0.9)))
c(mean(ols.beta[[1]]),sd(ols.beta[[1]]),quantile(ols.beta[[1]], probs = c(0.1, 0.5 ,0.9)))
# Compute desired summary statistics across the simulations
ols.results = foreach(j=1:length(gamma.vec)) %do%
c(mean(ols.beta[[j]]),sd(ols.beta[[j]]),quantile(ols.beta[[j]], probs = c(0.1, 0.5 ,0.9)))
View(ols.results)
o = c(mean(ols.beta[[1]]),sd(ols.beta[[1]]),quantile(ols.beta[[1]], probs = c(0.1, 0.5 ,0.9)))
p = c(mean(ols.se[[1]]),sd(ols.se[[1]]),quantile(ols.se[[1]], probs = c(0.1, 0.5 ,0.9)))
rbind(o.p)
rbind(o,p)
# Compute desired summary statistics across the simulations
ols.results = foreach(j=1:length(gamma.vec)) %do%
o = c(mean(ols.beta[[j]]),sd(ols.beta[[j]]),quantile(ols.beta[[j]], probs = c(0.1, 0.5 ,0.9)))
# Compute desired summary statistics across the simulations
ols.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(ols.beta[[j]]),sd(ols.beta[[j]]),quantile(ols.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(ols.se[[j]]),sd(ols.se[[j]]),quantile(ols.se[[j]], probs = c(0.1, 0.5 ,0.9))))
View(ols.results)
ols.results[[1]]
# Compute desired summary statistics across the simulations
ols.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(ols.beta[[j]]),sd(ols.beta[[j]]),quantile(ols.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(ols.se[[j]]),sd(ols.se[[j]]),quantile(ols.se[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(ols.rej[[j]]),sd(ols.rej[[j]]),quantile(ols.rej[[j]], probs = c(0.1, 0.5 ,0.9))))
ols.results[[1]]
ivreg(Y[,1]~X[[1]][,1]-1|W[,1,1])
# Run 2SLS for each gamma and each simulation -- this spits out 5000 ivreg's for each gamma
iv.big = foreach(j=1:length(gamma.vec)) %do%
lapply(1:M, function(i) ivreg(Y[,i]~X[[j]][,i]-1|W[,1,i]))
# Remove OLS results!
rm(ols.big)
# Remove big objects!
rm(ols.big,ols.beta,ols.se,ols.t,ols.rej)
ivreg(Y[,1]~X[[1]][,1]-1|W[,1,1])$coefficients
coef(ivreg(Y[,1]~X[[1]][,1]-1|W[,1,1]))[,"Std. Error"]
coef(ivreg(Y[,1]~X[[1]][,1]-1|W[,1,1]))
ans = ivreg(Y[,1]~X[[1]][,1]-1|W[,1,1])
summary.ans
summary(ans)
summary(ans)[["coefficients"]]
summary(ans)[["coefficients"]][,"Std. Error"]
iv.big[[1]][[1]])[["coefficients"]][,"Std. Error"]
iv.big[[1]][[1]][["coefficients"]][,"Std. Error"]
summary(iv.big[[1]][[1]])[["coefficients"]][,"Std. Error"]
summary(iv.big[[1]][[1]])[["coefficients"]][,"t value"]
# Extract point estimates, standard errors, t-stats
iv.beta = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) iv.big[[j]][[i]]$coefficients)
iv.se   = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) summary(iv.big[[j]][[i]])[["coefficients"]][,"Std. Error"])
iv.t    = sapply(1:length(gamma.vec),function(j) iv.beta[[j]]/iv.se[[j]])
iv.rej  = ifelse(iv.t>1.96,1,0)
# Combine results for each gamma
iv.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(iv.beta[[j]]),sd(iv.beta[[j]]),quantile(iv.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.se[[j]]),sd(iv.se[[j]]),quantile(iv.se[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.rej[[j]]),sd(iv.rej[[j]]),quantile(iv.rej[[j]], probs = c(0.1, 0.5 ,0.9))))
View(iv.results)
iv.results[[1]]
ols.results[[1]]
ols.results[[2]]
ols.results[[3]]
ols.results[[4]]
View(iv.t)
View(iv.rej)
# Combine results for each gamma
iv.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(iv.beta[[j]]),sd(iv.beta[[j]]),quantile(iv.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.se[[j]]),sd(iv.se[[j]]),quantile(iv.se[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.rej[,j]),sd(iv.rej[,j]),quantile(iv.rej[,j], probs = c(0.1, 0.5 ,0.9))))
View(iv.results)
View(iv.rej)
iv.reg[,1]
iv.rej[,1]
mean(iv.rej[,1])
c(mean(iv.rej[,1]),sd(iv.rej[,1]),quantile(iv.rej[,1], probs = c(0.1, 0.5 ,0.9))))
c(mean(iv.rej[,1]),sd(iv.rej[,1]),quantile(iv.rej[,1], probs = c(0.1, 0.5 ,0.9)))
# Combine results for each gamma
iv.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(iv.beta[[j]]),sd(iv.beta[[j]]),quantile(iv.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.se[[j]]),sd(iv.se[[j]]),quantile(iv.se[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.rej[,j]),sd(iv.rej[,j]),quantile(iv.rej[,j], probs = c(0.1, 0.5 ,0.9))))
View(iv.results)
c(mean(iv.rej[,1]),sd(iv.rej[,1]),quantile(iv.rej[,1], probs = c(0.1, 0.5 ,0.9)))
rm(iv.results)
# Combine results for each gamma
iv.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(iv.beta[[j]]),sd(iv.beta[[j]]),quantile(iv.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.se[[j]]),sd(iv.se[[j]]),quantile(iv.se[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.rej[,j]),sd(iv.rej[,j]),quantile(iv.rej[,j], probs = c(0.1, 0.5 ,0.9))))
View(iv.results)
lm(X[[1]][,1]~W[,1,1]-1)
ans=lm(X[[1]][,1]~W[,1,1]-1)
summary(ans)
summary(ans)[["coefficients"]]
summary(ans)[["statistic"]]
summary(ans)
summary(ans)["F-statistic"]
summary(ans)[["F-statistic"]]
ans$fstatstic
summary(ans)$fstatistic
summary(ans)$fstatistic["value"]
summary(ans)$fstatistic[1]
typeof(summary(ans)$fstatistic)
typeof(summary(ans)$fstatistic[1])
# Run first-stage regression and extract F-statistics
iv.f       = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) summary(lm(X[[j]][,i]~W[,1,i]-1))$fstatistic[1])
View(iv.f)
rm(iv.results)
# Combine results for each gamma
iv.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(iv.beta[[j]]),sd(iv.beta[[j]]),quantile(iv.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.se[[j]]),sd(iv.se[[j]]),quantile(iv.se[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.rej[,j]),sd(iv.rej[,j]),quantile(iv.rej[,j], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.f[[j]]),sd(iv.f[[j]]),quantile(iv.f[[j]], probs = c(0.1, 0.5 ,0.9))))
View(iv.results)
iv.results[[1]]
iv.results[[2]]
iv.results[[3]]
iv.results[[4]
iv.results[[4]]
# Run OLS for each gamma and each simulation -- this spits out 5000 lm's for each gamma
ols.big = foreach(j=1:length(gamma.vec)) %do%
lapply(1:M, function(i) lm(Y[,i]~X[[j]][,i]-1))
# Extract point estimates, standard errors, t-stats
ols.beta = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) ols.big[[j]][[i]]$coefficients)
ols.se   = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) coef(summary(ols.big[[j]][[i]]))[,"Std. Error"])
ols.t    = sapply(1:length(gamma.vec),function(j) ols.beta[[j]]/ols.se[[j]])
ols.rej  = ifelse(ols.t>1.96,1,0)
rm(ols.results)
# Compute desired summary statistics across the simulations (spits out a list containing results for each gamma)
ols.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(ols.beta[[j]]),sd(ols.beta[[j]]),quantile(ols.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(ols.se[[j]]),sd(ols.se[[j]]),quantile(ols.se[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(ols.rej[,j]),sd(ols.rej[,j]),quantile(ols.rej[,j], probs = c(0.1, 0.5 ,0.9))))
View(ols.results)
# Remove big objects!
rm(ols.big,ols.beta,ols.se,ols.t,ols.rej)
# Remove big objects!
rm(iv.big,iv.beta,iv.se,iv.t,iv.rej,iv.f)
round(iv.results[[1]])
round(iv.results[[1]],2)
round(iv.results[[1]],3)
round(iv.results[[1]],3)
round(ols.results[[1]],3)
round(ols.results[[2]],3)
round(iv.results[[2]],3)
round(iv.results[[3]],3)
round(ols.results[[3]],3)
round(iv.results[[4]],3)
round(ols.results[[4]],3)
######################################################################
# Load packages, clear workspace
######################################################################
rm(list = ls())             #clear workspace
## ECON641: PROBLEM SET 2
## Q1: THE FIRM SIZE DISTRIBUTION
## Anirudh Yadav
## 12/07/2018
######################################################################
# Load packages, clear workspace
######################################################################
rm(list = ls())             #clear workspace
library(foreach)            #for looping
library(data.table)         #for data manipulation
library(Matrix)             #fast matrix calcs
library(ggplot2)            #for pretty plots
library(sandwich)           #for variance-covariance estimation
library(xtable)             #for latex tables
library(readstata13)        #for reading Stata dta files
options(scipen = 999)       #forces R to use normal numbers instead of scientific notation
######################################################################
# Input data & create new variables
######################################################################
setwd("/Users/Anirudh/Desktop/GitHub/PhD_Coursework/ECON641/HW2")
data = as.data.table(read.dta13('PanelAnnual_compustat1980_2015.dta'))
# Create 1 digit SIC codes
data[,sic1:=cut(sic,c(0,999,1999,3999,4999,5999,6999,8999,9999),labels=c("Ag","MinCon","Man","Tran","WRTrade","Fin","Serv","Pub"))]
# Create additional variables, by fyear
data[,`:=`(rsales=rank(-sale), remp=rank(-emp), logsale=log(sale),logemp=log(emp)), by=fyear]
# Create industry-level rankings
data[,`:=`(rsales.ind=rank(-sale), remp.ind=rank(-emp)), by=.(fyear,sic1)]
# Keep only 2015 & 1985 data
data=data[fyear==2015|fyear==1985]
# Plot 4 -- full sample, by industry
p2015.all.ind = ggplot(data[fyear==2015],aes(x=logsale,y=log(rsales.ind)))+
geom_point()+
xlab("log(Sales)")+ylab("log(Rank)") + facet_wrap(~sic1)
# Plot 5 -- top 100 firms, by industry
p2015.all.ind = ggplot(data[fyear==2015 & rsales.ind<=100],aes(x=logsale,y=log(rsales.ind)))+
geom_point()+
xlab("log(Sales)")+ylab("log(Rank)") + facet_wrap(~sic1)
p2015.all.ind
## ECON641: PROBLEM SET 2
## Q1: THE FIRM SIZE DISTRIBUTION
## Anirudh Yadav
## 12/07/2018
######################################################################
# Load packages, clear workspace
######################################################################
rm(list = ls())             #clear workspace
library(foreach)            #for looping
library(data.table)         #for data manipulation
library(Matrix)             #fast matrix calcs
library(ggplot2)            #for pretty plots
library(sandwich)           #for variance-covariance estimation
library(xtable)             #for latex tables
library(readstata13)        #for reading Stata dta files
options(scipen = 999)       #forces R to use normal numbers instead of scientific notation
######################################################################
# Input data & create new variables
######################################################################
setwd("/Users/Anirudh/Desktop/GitHub/PhD_Coursework/ECON641/HW2")
data = as.data.table(read.dta13('PanelAnnual_compustat1980_2015.dta'))
# Create 1 digit SIC codes
data[,sic1:=cut(sic,c(0,999,1999,3999,4999,5999,6999,8999,9999),labels=c("Agriculture","Mining + Construction","Manufacturing","Transport, etc.","Wholesale +Retail Trade","Finance, etc.","Services","Public Admin"))]
# Create additional variables, by fyear
data[,`:=`(rsales=rank(-sale), remp=rank(-emp), logsale=log(sale),logemp=log(emp)), by=fyear]
# Create industry-level rankings
data[,`:=`(rsales.ind=rank(-sale), remp.ind=rank(-emp)), by=.(fyear,sic1)]
# Keep only 2015 & 1985 data
data=data[fyear==2015|fyear==1985]
# Plot 4 -- full sample, by industry
p2015.all.ind = ggplot(data[fyear==2015],aes(x=logsale,y=log(rsales.ind)))+
geom_point()+
xlab("log(Sales)")+ylab("log(Rank)") + facet_wrap(~sic1)
p2015.all.ind
## ECON641: PROBLEM SET 2
## Q1: THE FIRM SIZE DISTRIBUTION
## Anirudh Yadav
## 12/07/2018
######################################################################
# Load packages, clear workspace
######################################################################
rm(list = ls())             #clear workspace
library(foreach)            #for looping
library(data.table)         #for data manipulation
library(Matrix)             #fast matrix calcs
library(ggplot2)            #for pretty plots
library(sandwich)           #for variance-covariance estimation
library(xtable)             #for latex tables
library(readstata13)        #for reading Stata dta files
options(scipen = 999)       #forces R to use normal numbers instead of scientific notation
######################################################################
# Input data & create new variables
######################################################################
setwd("/Users/Anirudh/Desktop/GitHub/PhD_Coursework/ECON641/HW2")
data = as.data.table(read.dta13('PanelAnnual_compustat1980_2015.dta'))
# Create 1 digit SIC codes
data[,sic1:=cut(sic,c(0,999,1999,3999,4999,5999,6999,8999,9999),labels=c("Agriculture","Mining + Construction","Manufacturing","Transport, etc.","Wholesale + Retail Trade","Finance, etc.","Services","Public Admin"))]
# Create additional variables, by fyear
data[,`:=`(rsales=rank(-sale), remp=rank(-emp), logsale=log(sale),logemp=log(emp)), by=fyear]
# Create industry-level rankings
data[,`:=`(rsales.ind=rank(-sale), remp.ind=rank(-emp)), by=.(fyear,sic1)]
# Keep only 2015 & 1985 data
data=data[fyear==2015|fyear==1985]
# Plot 4 -- full sample, by industry
p2015.all.ind = ggplot(data[fyear==2015],aes(x=logsale,y=log(rsales.ind)))+
geom_point()+
xlab("log(Sales)")+ylab("log(Rank)") + facet_wrap(~sic1)
p2015.all.ind
# Plot 5 -- top 100 firms, by industry
p2015.all.ind = ggplot(data[fyear==2015 & rsales.ind<=100],aes(x=logsale,y=log(rsales.ind)))+
geom_point()+
xlab("log(Sales)")+ylab("log(Rank)") + facet_wrap(~sic1)
p2015.all.ind
# Plot 5 -- top 100 firms, by industry
p2015.all.ind = ggplot(data[fyear==2015 & rsales.ind<=100 & sic1!=c("Agricultre","Public Admin")],aes(x=logsale,y=log(rsales.ind)))+
geom_point()+
xlab("log(Sales)")+ylab("log(Rank)") + facet_wrap(~sic1)
# Plot 5 -- top 100 firms, by industry
p2015.all.ind = ggplot(data[fyear==2015 & rsales.ind<=100 & sic1!="Agricultre" & sic1!="Public Admin")],aes(x=logsale,y=log(rsales.ind)))+
geom_point()+
xlab("log(Sales)")+ylab("log(Rank)") + facet_wrap(~sic1)
# Plot 5 -- top 100 firms, by industry
p2015.all.ind = ggplot(data[fyear==2015 & rsales.ind<=100 & sic1!="Agriculture" & sic1!="Public Admin")],aes(x=logsale,y=log(rsales.ind)))+
geom_point()+
xlab("log(Sales)")+ylab("log(Rank)") + facet_wrap(~sic1)
# Plot 5 -- top 100 firms, by industry
p2015.all.ind = ggplot(data[fyear==2015 & rsales.ind<=100 & sic1!="Agriculture" & sic1!="Public Admin")],aes(x=logsale,y=log(rsales.ind)))+ geom_point()+ xlab("log(Sales)")+ylab("log(Rank)") + facet_wrap(~sic1)
# Plot 5 -- top 100 firms, by industry
p2015.all.ind = ggplot(data[fyear==2015 & rsales.ind<=100 & sic1!="Agriculture" & sic1!="Public Admin"],aes(x=logsale,y=log(rsales.ind)))+ geom_point()+ xlab("log(Sales)")+ylab("log(Rank)") + facet_wrap(~sic1)
p2015.all.ind
p2015.100.ind.ex = ggplot(data[fyear==2015 & rsales.ind<=50 & sic1!="Agriculture" & sic1!="Public Admin"],aes(x=logsale,y=log(rsales.ind)))+
geom_point()+
xlab("log(Sales)")+ylab("log(Rank)") + facet_wrap(~sic1)
p2015.all.ind
ggplot(data[fyear==2015 & rsales.ind<=50 & sic1!="Agriculture" & sic1!="Public Admin"],aes(x=logsale,y=log(rsales.ind)))+
geom_point()+
xlab("log(Sales)")+ylab("log(Rank)") + facet_wrap(~sic1)
ggplot(data[fyear==2015 & rsales.ind<=50 & sic1="Agriculture"],aes(x=logsale,y=log(rsales.ind)))+
geom_point()+
xlab("log(Sales)")+ylab("log(Rank)")
ggplot(data[fyear==2015 & rsales.ind<=50 & sic1="Agriculture"],aes(x=logsale,y=log(rsales.ind)))+
geom_point()+ xlab("log(Sales)")+ylab("log(Rank)")
ggplot(data[fyear==2015 & rsales.ind<=50 & sic1="Agriculture"],aes(x=logsale,y=log(rsales.ind)))+ geom_point()+ xlab("log(Sales)")+ylab("log(Rank)")
ggplot(data[fyear==2015 & rsales.ind<=50 & sic1=="Agriculture"],aes(x=logsale,y=log(rsales.ind)))+ geom_point()+ xlab("log(Sales)")+ylab("log(Rank)")
ggplot(data[fyear==2015 & rsales.ind<=100 & sic1=="Agriculture"],aes(x=logsale,y=log(rsales.ind)))+ geom_point()+ xlab("log(Sales)")+ylab("log(Rank)")
ggplot(data[fyear==2015 & rsales.ind<=500 & sic1=="Agriculture"],aes(x=logsale,y=log(rsales.ind)))+ geom_point()+ xlab("log(Sales)")+ylab("log(Rank)")
ggplot(data[fyear==2015 & sic1=="Agriculture"],aes(x=logsale,y=log(rsales.ind)))+ geom_point()+ xlab("log(Sales)")+ylab("log(Rank)")
ggplot(data[fyear==2015 & sic1=="Public Admin"],aes(x=logsale,y=log(rsales.ind)))+ geom_point()+ xlab("log(Sales)")+ylab("log(Rank)")
# Run OLS regs
sales.regs = foreach(j=ind.vec)%:%
foreach(i=cutoffs.ind) %do%{
lm(log(rsales.ind-0.5)~logsale,data[fyear==2015 & rsales.ind<=i & logsale!=-Inf] & sic1=j)
}
# Run OLS regs
sales.regs = foreach(j=ind.vec,.combine='cbind')%:%
foreach(i=cutoffs.ind, .combine = 'c') %do%{
lm(log(rsales.ind-0.5)~logsale,data[fyear==2015 & rsales.ind<=i & logsale!=-Inf] & sic1=j)
}
# Run OLS regs
sales.regs = foreach(j=ind.vec,.combine='cbind')%:%
foreach(i=cutoffs.ind, .combine = 'c') %do%{
lm(log(rsales.ind-0.5)~logsale,data[fyear==2015 & rsales.ind<=i & logsale!=-Inf] & sic1=j])
}
lm(log(rsales.ind-0.5)~logsale,data[fyear==2015 & rsales.ind<=i & logsale!=-Inf & sic1==j])
cutoffs.ind = c(length(data[fyear==2015,rsales]),100,50)
ind.vec = c("Agriculture","Mining + Construction","Manufacturing","Transport, etc.","Wholesale + Retail Trade","Finance, etc.","Services","Public Admin")
# Run OLS regs
sales.regs = foreach(j=ind.vec,.combine='cbind')%:%
foreach(i=cutoffs.ind, .combine = 'c') %do%{
lm(log(rsales.ind-0.5)~logsale,data[fyear==2015 & rsales.ind<=i & logsale!=-Inf & sic1==j])
}
View(sales.regs)
# Run OLS regs -- spits out a big list of 3 x 8 x 12 (i.e. 24 regressions)
sales.regs.ind = foreach(j=ind.vec,.combine='c')%:%
foreach(i=cutoffs.ind, .combine = 'c') %do%{
lm(log(rsales.ind-0.5)~logsale,data[fyear==2015 & rsales.ind<=i & logsale!=-Inf & sic1==j])
}
View(sales.regs.ind)
# Run OLS regs -- spits out a big list of 3 x 8 x 12 (i.e. 24 regressions)
sales.regs.ind = foreach(j=ind.vec,.combine='c')%:%
foreach(i=cutoffs.ind, .combine = 'cbind') %do%{
lm(log(rsales.ind-0.5)~logsale,data[fyear==2015 & rsales.ind<=i & logsale!=-Inf & sic1==j])
}
View(sales.regs.ind)
summary(sales.regs.ind[[1]])
# Run OLS regs -- spits out a big list of 3 x 8 x 12 (i.e. 24 regressions)
sales.regs.ind = foreach(j=ind.vec,.combine='cbind')%:%
foreach(i=cutoffs.ind, .combine = 'c') %do%{
lm(log(rsales.ind-0.5)~logsale,data[fyear==2015 & rsales.ind<=i & logsale!=-Inf & sic1==j])
}
View(sales.regs.ind)
sales.regs.ind[[1]]
