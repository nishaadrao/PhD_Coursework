sapply(1:M, function(i) ols.big[[j]][[i]]$coefficients)
View(ols.beta)
coef(summary(ols.big[[1]][[1]]))[, "Std. Error"]
View(ols.big)
ols.se   = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) summary(ols.big[[j]][[i]])[,"Std. Error"])
summary(ols.big[[1]][[1]])[,"Std. Error"]
ols.se   = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) coef(summary(ols.big[[j]][[i]]))[,"Std. Error"])
View(ols.se)
ols.beta/ols.se
ols.beta[[1]]/ols.se[[1]]
ols.t    = sapply(j=1:length(gamma.vec),ols.beta[[j]]/ols.se[[j]])
ols.t    = sapply(j=1:length(gamma.vec),function(j) ols.beta[[j]]/ols.se[[j]])
ols.t    = sapply(1:length(gamma.vec),function(j) ols.beta[[j]]/ols.se[[j]])
View(ols.t)
ols.reg  = ifelse(ols.t>1.96,1,0)
View(ols.reg)
ols.rej  = ifelse(ols.t>1.96,1,0)
rm(ols.reg)
View(ols.rej)
summary(ols.beta[[1]])
seq(0, 1, 0.25)
quantile(ols.beta[[1]], probs = c(0.1, 0.5 ,0.9))
cbind(mean(ols.beta[[1]]),quantile(ols.beta[[1]], probs = c(0.1, 0.5 ,0.9)))
c(mean(ols.beta[[1]]),quantile(ols.beta[[1]], probs = c(0.1, 0.5 ,0.9)))
c(mean(ols.beta[[1]]),sd(ols.beta[[1]]),quantile(ols.beta[[1]], probs = c(0.1, 0.5 ,0.9)))
# Compute desired summary statistics across the simulations
ols.results = foreach(j=1:length(gamma.vec)) %do%
c(mean(ols.beta[[j]]),sd(ols.beta[[j]]),quantile(ols.beta[[j]], probs = c(0.1, 0.5 ,0.9)))
View(ols.results)
o = c(mean(ols.beta[[1]]),sd(ols.beta[[1]]),quantile(ols.beta[[1]], probs = c(0.1, 0.5 ,0.9)))
p = c(mean(ols.se[[1]]),sd(ols.se[[1]]),quantile(ols.se[[1]], probs = c(0.1, 0.5 ,0.9)))
rbind(o.p)
rbind(o,p)
# Compute desired summary statistics across the simulations
ols.results = foreach(j=1:length(gamma.vec)) %do%
o = c(mean(ols.beta[[j]]),sd(ols.beta[[j]]),quantile(ols.beta[[j]], probs = c(0.1, 0.5 ,0.9)))
# Compute desired summary statistics across the simulations
ols.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(ols.beta[[j]]),sd(ols.beta[[j]]),quantile(ols.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(ols.se[[j]]),sd(ols.se[[j]]),quantile(ols.se[[j]], probs = c(0.1, 0.5 ,0.9))))
View(ols.results)
ols.results[[1]]
# Compute desired summary statistics across the simulations
ols.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(ols.beta[[j]]),sd(ols.beta[[j]]),quantile(ols.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(ols.se[[j]]),sd(ols.se[[j]]),quantile(ols.se[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(ols.rej[[j]]),sd(ols.rej[[j]]),quantile(ols.rej[[j]], probs = c(0.1, 0.5 ,0.9))))
ols.results[[1]]
ivreg(Y[,1]~X[[1]][,1]-1|W[,1,1])
# Run 2SLS for each gamma and each simulation -- this spits out 5000 ivreg's for each gamma
iv.big = foreach(j=1:length(gamma.vec)) %do%
lapply(1:M, function(i) ivreg(Y[,i]~X[[j]][,i]-1|W[,1,i]))
# Remove OLS results!
rm(ols.big)
# Remove big objects!
rm(ols.big,ols.beta,ols.se,ols.t,ols.rej)
ivreg(Y[,1]~X[[1]][,1]-1|W[,1,1])$coefficients
coef(ivreg(Y[,1]~X[[1]][,1]-1|W[,1,1]))[,"Std. Error"]
coef(ivreg(Y[,1]~X[[1]][,1]-1|W[,1,1]))
ans = ivreg(Y[,1]~X[[1]][,1]-1|W[,1,1])
summary.ans
summary(ans)
summary(ans)[["coefficients"]]
summary(ans)[["coefficients"]][,"Std. Error"]
iv.big[[1]][[1]])[["coefficients"]][,"Std. Error"]
iv.big[[1]][[1]][["coefficients"]][,"Std. Error"]
summary(iv.big[[1]][[1]])[["coefficients"]][,"Std. Error"]
summary(iv.big[[1]][[1]])[["coefficients"]][,"t value"]
# Extract point estimates, standard errors, t-stats
iv.beta = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) iv.big[[j]][[i]]$coefficients)
iv.se   = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) summary(iv.big[[j]][[i]])[["coefficients"]][,"Std. Error"])
iv.t    = sapply(1:length(gamma.vec),function(j) iv.beta[[j]]/iv.se[[j]])
iv.rej  = ifelse(iv.t>1.96,1,0)
# Combine results for each gamma
iv.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(iv.beta[[j]]),sd(iv.beta[[j]]),quantile(iv.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.se[[j]]),sd(iv.se[[j]]),quantile(iv.se[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.rej[[j]]),sd(iv.rej[[j]]),quantile(iv.rej[[j]], probs = c(0.1, 0.5 ,0.9))))
View(iv.results)
iv.results[[1]]
ols.results[[1]]
ols.results[[2]]
ols.results[[3]]
ols.results[[4]]
View(iv.t)
View(iv.rej)
# Combine results for each gamma
iv.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(iv.beta[[j]]),sd(iv.beta[[j]]),quantile(iv.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.se[[j]]),sd(iv.se[[j]]),quantile(iv.se[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.rej[,j]),sd(iv.rej[,j]),quantile(iv.rej[,j], probs = c(0.1, 0.5 ,0.9))))
View(iv.results)
View(iv.rej)
iv.reg[,1]
iv.rej[,1]
mean(iv.rej[,1])
c(mean(iv.rej[,1]),sd(iv.rej[,1]),quantile(iv.rej[,1], probs = c(0.1, 0.5 ,0.9))))
c(mean(iv.rej[,1]),sd(iv.rej[,1]),quantile(iv.rej[,1], probs = c(0.1, 0.5 ,0.9)))
# Combine results for each gamma
iv.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(iv.beta[[j]]),sd(iv.beta[[j]]),quantile(iv.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.se[[j]]),sd(iv.se[[j]]),quantile(iv.se[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.rej[,j]),sd(iv.rej[,j]),quantile(iv.rej[,j], probs = c(0.1, 0.5 ,0.9))))
View(iv.results)
c(mean(iv.rej[,1]),sd(iv.rej[,1]),quantile(iv.rej[,1], probs = c(0.1, 0.5 ,0.9)))
rm(iv.results)
# Combine results for each gamma
iv.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(iv.beta[[j]]),sd(iv.beta[[j]]),quantile(iv.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.se[[j]]),sd(iv.se[[j]]),quantile(iv.se[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.rej[,j]),sd(iv.rej[,j]),quantile(iv.rej[,j], probs = c(0.1, 0.5 ,0.9))))
View(iv.results)
lm(X[[1]][,1]~W[,1,1]-1)
ans=lm(X[[1]][,1]~W[,1,1]-1)
summary(ans)
summary(ans)[["coefficients"]]
summary(ans)[["statistic"]]
summary(ans)
summary(ans)["F-statistic"]
summary(ans)[["F-statistic"]]
ans$fstatstic
summary(ans)$fstatistic
summary(ans)$fstatistic["value"]
summary(ans)$fstatistic[1]
typeof(summary(ans)$fstatistic)
typeof(summary(ans)$fstatistic[1])
# Run first-stage regression and extract F-statistics
iv.f       = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) summary(lm(X[[j]][,i]~W[,1,i]-1))$fstatistic[1])
View(iv.f)
rm(iv.results)
# Combine results for each gamma
iv.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(iv.beta[[j]]),sd(iv.beta[[j]]),quantile(iv.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.se[[j]]),sd(iv.se[[j]]),quantile(iv.se[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.rej[,j]),sd(iv.rej[,j]),quantile(iv.rej[,j], probs = c(0.1, 0.5 ,0.9))),
c(mean(iv.f[[j]]),sd(iv.f[[j]]),quantile(iv.f[[j]], probs = c(0.1, 0.5 ,0.9))))
View(iv.results)
iv.results[[1]]
iv.results[[2]]
iv.results[[3]]
iv.results[[4]
iv.results[[4]]
# Run OLS for each gamma and each simulation -- this spits out 5000 lm's for each gamma
ols.big = foreach(j=1:length(gamma.vec)) %do%
lapply(1:M, function(i) lm(Y[,i]~X[[j]][,i]-1))
# Extract point estimates, standard errors, t-stats
ols.beta = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) ols.big[[j]][[i]]$coefficients)
ols.se   = foreach(j=1:length(gamma.vec)) %do%
sapply(1:M, function(i) coef(summary(ols.big[[j]][[i]]))[,"Std. Error"])
ols.t    = sapply(1:length(gamma.vec),function(j) ols.beta[[j]]/ols.se[[j]])
ols.rej  = ifelse(ols.t>1.96,1,0)
rm(ols.results)
# Compute desired summary statistics across the simulations (spits out a list containing results for each gamma)
ols.results = foreach(j=1:length(gamma.vec)) %do%
rbind(c(mean(ols.beta[[j]]),sd(ols.beta[[j]]),quantile(ols.beta[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(ols.se[[j]]),sd(ols.se[[j]]),quantile(ols.se[[j]], probs = c(0.1, 0.5 ,0.9))),
c(mean(ols.rej[,j]),sd(ols.rej[,j]),quantile(ols.rej[,j], probs = c(0.1, 0.5 ,0.9))))
View(ols.results)
# Remove big objects!
rm(ols.big,ols.beta,ols.se,ols.t,ols.rej)
# Remove big objects!
rm(iv.big,iv.beta,iv.se,iv.t,iv.rej,iv.f)
round(iv.results[[1]])
round(iv.results[[1]],2)
round(iv.results[[1]],3)
round(iv.results[[1]],3)
round(ols.results[[1]],3)
round(ols.results[[2]],3)
round(iv.results[[2]],3)
round(iv.results[[3]],3)
round(ols.results[[3]],3)
round(iv.results[[4]],3)
round(ols.results[[4]],3)
######################################################################
# Load packages, clear workspace
######################################################################
rm(list = ls())             #clear workspace
## ECON675: ASSIGNMENT 5
## Q2: WEAK INSTRUMENTS SIMULATIONS
## Anirudh Yadav
## 11/19/2018
######################################################################
# Load packages, clear workspace
######################################################################
rm(list = ls())             #clear workspace
library(foreach)            #for looping
library(data.table)         #for data manipulation
library(Matrix)             #fast matrix calcs
library(ggplot2)            #for pretty plots
library(sandwich)           #for variance-covariance estimation
library(xtable)             #for latex tables
library(boot)               #for bootstrapping
library(mvtnorm)            #for MVN stuff
library(AER)                #for IV regressions
options(scipen = 999)       #forces R to use normal numbers instead of scientific notation
######################################################################
# Input data
######################################################################
data <- as.data.table(read.csv('PhD_Coursework/ECON675/HW6/HeadStart.csv'))
install.packages('rdrobust')
library(rdrobust)
View(data)
data[,povrate60]
typeof(data[,povrate60])
rdplot(data[,mort_related_pre],data[,povrate60],binselect = "es")
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "es")
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "esmv")
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "esmv",x.label="povrate60",y.label="mort_related_pre")
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "esmv",x.label="povrate60",y.label="mort_related_pre",title="")
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "esmv",x.label="povrate60",y.label="mort_related_pre",title="",ci=TRUE)
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "esmv",x.label="povrate60",y.label="mort_related_pre",title="",shade=TRUE)
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "esmv",x.label="povrate60",y.label="mort_related_pre",title="",shade=TRUE,ci=TRUE)
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "esmv",x.label="povrate60",y.label="mort_related_pre",title="",ci=TRUE,shade=TRUE)
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "esmv",x.label="povrate60",y.label="mort_related_pre",title="",ci=TRUE)
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "esmv",x.label="povrate60",y.label="mort_related_pre",title="")
wd()
getwd()
setwd("/Users/Anirudh/Desktop/GitHub/PhD_Coursework/ECON675/HW6")
getwd()
## ECON675: ASSIGNMENT 5
## Q2: WEAK INSTRUMENTS SIMULATIONS
## Anirudh Yadav
## 11/19/2018
######################################################################
# Load packages, clear workspace
######################################################################
rm(list = ls())             #clear workspace
library(foreach)            #for looping
library(data.table)         #for data manipulation
library(Matrix)             #fast matrix calcs
library(ggplot2)            #for pretty plots
library(sandwich)           #for variance-covariance estimation
library(xtable)             #for latex tables
library(rdrobust)           #for RD stuff
options(scipen = 999)       #forces R to use normal numbers instead of scientific notation
######################################################################
# Input data
######################################################################
setwd("/Users/Anirudh/Desktop/GitHub/PhD_Coursework/ECON675/HW6")
data <- as.data.table(read.csv('HeadStart.csv'))
# Evenly-spaced bins, IMSE optimal
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "es",x.label="povrate60",y.label="mort_related_pre",title="")
# Evenly-spaced bins, mimicking variance
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "esmv",x.label="povrate60",y.label="mort_related_pre",title="")
# Quantile-spaced bins, IMSE optimal
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "qs",x.label="povrate60",y.label="mort_related_pre",title="")
# Quantile-spaced bins, mimicking variance
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "qsmv",x.label="povrate60",y.label="mort_related_pre",title="")
dev.copy(pdf,'q2-1-qsmv.pdf')
dev.off()
## ECON675: ASSIGNMENT 5
## Q2: WEAK INSTRUMENTS SIMULATIONS
## Anirudh Yadav
## 11/19/2018
######################################################################
# Load packages, clear workspace
######################################################################
rm(list = ls())             #clear workspace
library(foreach)            #for looping
library(data.table)         #for data manipulation
library(Matrix)             #fast matrix calcs
library(ggplot2)            #for pretty plots
library(sandwich)           #for variance-covariance estimation
library(xtable)             #for latex tables
library(rdrobust)           #for RD stuff
options(scipen = 999)       #forces R to use normal numbers instead of scientific notation
######################################################################
# Input data
######################################################################
setwd("/Users/Anirudh/Desktop/GitHub/PhD_Coursework/ECON675/HW6")
data <- as.data.table(read.csv('HeadStart.csv'))
######################################################################
# [2.1] RD Plots and falsification tests
######################################################################
# Evenly-spaced bins, IMSE optimal
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "es",x.label="povrate60",y.label="mort_related_pre",title="")
dev.copy(pdf,'q2-1-es')
dev.off()
# Evenly-spaced bins, mimicking variance
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "esmv",x.label="povrate60",y.label="mort_related_pre",title="")
dev.copy(pdf,'q2-1-esmv.pdf')
dev.off()
# Quantile-spaced bins, IMSE optimal
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "qs",x.label="povrate60",y.label="mort_related_pre",title="")
dev.copy(pdf,'q2-1-qs.pdf')
dev.off()
# Quantile-spaced bins, mimicking variance
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "qsmv",x.label="povrate60",y.label="mort_related_pre",title="")
dev.copy(pdf,'q2-1-qsmv.pdf')
dev.off()
## ECON675: ASSIGNMENT 5
## Q2: WEAK INSTRUMENTS SIMULATIONS
## Anirudh Yadav
## 11/19/2018
######################################################################
# Load packages, clear workspace
######################################################################
rm(list = ls())             #clear workspace
library(foreach)            #for looping
library(data.table)         #for data manipulation
library(Matrix)             #fast matrix calcs
library(ggplot2)            #for pretty plots
library(sandwich)           #for variance-covariance estimation
library(xtable)             #for latex tables
library(rdrobust)           #for RD stuff
options(scipen = 999)       #forces R to use normal numbers instead of scientific notation
######################################################################
# Input data
######################################################################
setwd("/Users/Anirudh/Desktop/GitHub/PhD_Coursework/ECON675/HW6")
data <- as.data.table(read.csv('HeadStart.csv'))
######################################################################
# [2.1] RD Plots and falsification tests
######################################################################
# Evenly-spaced bins, IMSE optimal
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "es",x.label="povrate60",y.label="mort_related_pre",title="")
dev.copy(pdf,'q2-1-es.pdf')
dev.off()
# Evenly-spaced bins, mimicking variance
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "esmv",x.label="povrate60",y.label="mort_related_pre",title="")
dev.copy(pdf,'q2-1-esmv.pdf')
dev.off()
# Quantile-spaced bins, IMSE optimal
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "qs",x.label="povrate60",y.label="mort_related_pre",title="")
dev.copy(pdf,'q2-1-qs.pdf')
dev.off()
# Quantile-spaced bins, mimicking variance
rdplot(data[,mort_related_pre],data[,povrate60],p=1,binselect = "qsmv",x.label="povrate60",y.label="mort_related_pre",title="")
dev.copy(pdf,'q2-1-qsmv.pdf')
dev.off()
histogram(data[,povrate60])
?hist
hist(data[,povrate60])
hist(data[,povrate60],desnity=TRUE)
hist(data[,povrate60],density=TRUE)
density(data[,povrate60])
plot(density(data[,povrate60]))
?density
plot(density(data[,povrate60]),bw="bcv")
plot(density(data[,povrate60],bw="bcv"))
?density
warnings()
hist(data[,povrate60],freq=FALSE)
1:2:10
1:1:10
1:2:11
c(1:1:10)
?seq
seq(1,10,1)
seq(1,10,1)=1:1:10
seq(1,10,1)==1:1:10
# Exact binomial tests for different windows around the cutoff
h.vec = [0.3:0.2:1.1]
# Exact binomial tests for different windows around the cutoff
h.vec = 0.3:0.2:1.1
h.vec
# Exact binomial tests for different windows around the cutoff
h.vec = seq(0.3,1.3,0.2)
count(data[,povrate60])
length(data[,povrate60])
length(data[,povrate60<10])
x     = data[,povrate60]
x < 10
x => -0.3 & x <= 0
x >= -0.3 & x <= 0
sum(x >= -0.3 & x <= 0)
N.l   = sapply(1:length(h.vec),function(i) sum(x >= -h.vec[i] & x <=0))
N.u   = sapply(1:length(h.vec),function(i) sum(x >= 0 & x <= h.vec[i]))
N.t   = N.l + N.u
binom.test(N.u[1],N.t[1])
o=binom.test(N.u[1],N.t[1])
View(o)
o$p.value
# Conduct exact binomial tests (p=0.5), where success is treatment and store p-vals
binom.pvals = sapply(1:length(h.vec),function(i) binom.test(N.u[i],N.t[i])$p.value)
cbind(h.vec,N.l,N.u,binom.pvals)
# Put results together for latex
binom.results = cbind(h.vec,N.l,N.u,binom.pvals)
xtable(binom.results)
xtable(binom.results,digits = c(0,1,0,0,3))
xtable(binom.results,digits = c(0,1,0,0,3),include.rownames=FALSE)
install.packages('rddensity')
library(rddensity)
rddensity(x)
o=rddensity(x)
View(o)
o=rddensity(x,p=1,kernel = "triangular")
o=rddensity(x,p=1,kernel = "triangular",h=c(9.213,9.213))
View(o)
o=rddensity(x,p=1,kernel = "triangular")
View(o)
o=rddensity(x,p=1)
View(o)
o=rddensity(x)
View(o)
x
o=rddensity(x)
View(o)
rddensity(x)
ans = rddensity(x)
rm(o)
View(ans)
ifelse(data[,povrate60]>=0,1,0)
# Create treatment dummy for regressions
data[t:=ifelse(povrate60>=0,1,0)]
# Create treatment dummy for regressions
data[,t:=ifelse(povrate60>=0,1,0)]
View(data)
# Create treatment dummy for regressions
data[,treat:=ifelse(povrate60>=0,1,0)]
View(data)
View(data)
# Create treatment dummy for regressions
treat=ifelse(data[,povrate60]>=0,1,0)
# Get outcome variable
Y = data[,mort_related_post]
# Generate covariates for polynomial regressions
X.3 = c(x,x^2,x^3)
# Generate covariates for polynomial regressions
X.3 = cbind(x,x^2,x^3)
View(X.3)
# Generate covariates for polynomial regressions
X.3 = cbind(x,x^2,x^3)
X.4 = cbind(x,x^2,x^3,x^4)
X.5 = cbind(x,x^2,x^3,x^4,x^5)
X.6 = cbind(x,x^2,x^3,x^4,x^5,x^6)
lm(Y ~ treat + X.3)
X.6[,c(1:3)]
X.6[,c(1:3+1)]
X.6[,c(1:4)]
X.6[,c(1:(3+1))]
# Run polynomial regressions
global.regs = lapply(1:4,function(i) lm(Y ~ treat + X.6[,c(1:(3+i))]))
# Run polynomial regressions
global.regs = lapply(0:3,function(i) lm(Y ~ treat + X.6[,c(1:(3+i))]))
View(global.regs)
global.regs[[1]]
global.regs[[1]]$coefficients
global.regs[[1]]$coefficients[1]
global.regs[[1]]$coefficients[2]
vcovHC(global.regs[[1]],"HC1")
diag(vcovHC(global.regs[[1]],"HC1"))
diag(vcovHC(global.regs[[1]],"HC1"))[2]
diag(vcovHC(global.regs[[1]],"HC2"))[2]
sqrt(diag(vcovHC(global.regs[[1]],"HC2")))[2]
# Get point estimates
global.betas = sapply(1:4,function(i) global.regs[[i]]$coefficients[2])
# Get robust SEs
global.SEs   = sapply(1:4,function(i) sqrt(diag(vcovHC(global.regs[[i]],"HC2")))[2])
# Put results together
global.results = rbind(global.betas, global.SEs)
xtable(global.results)
# Put results together
global.results = rbind(global.betas, global.SEs)
View(global.results)
colnames(global.results) = c(3,4,5,6)
View(global.results)
xtable(global.results,digits=c(2,2,2,2))
xtable(global.results,digits=c(0,2,2,2,2))
plot(x,global.regs[[1]]$fitted.values)
rdrobust(Y,x)
ans = rdrobust(Y,x)
View(ans)
ans = rdrobust(Y,x,all=TRUE)
View(ans)
ans$ci
summary(ans)
cbind(ans$coef,ans$se,ans$ci)
# MSE-optimal RD treatment effect estimates
rd.results = lapply(0:2, function(i) rdrobust(Y,x,p=i,all=TRUE))
# MSE-optimal RD treatment effect estimates
rd.regs = lapply(0:2, function(i) rdrobust(Y,x,p=i,all=TRUE))
# Combine results for different polynomial orders
rd.p0   = cbind(rd.regs[[1]]$coef,rd.regs[[1]]$se,rd.regs[[1]]$ci)
rd.p1   = cbind(rd.regs[[2]]$coef,rd.regs[[2]]$se,rd.regs[[2]]$ci)
rd.p2   = cbind(rd.regs[[3]]$coef,rd.regs[[3]]$se,rd.regs[[3]]$ci)
View(rd.p0)
xtable(rd.p0,digits=c(0,2,2,2,2))
xtable(rd.p1,digits=c(0,2,2,2,2))
xtable(rd.p2,digits=c(0,2,2,2,2))
View(data)
View(data)
# Robustness checks
rd.rob1 = rdrobust(Y,data[,mort_related_pre],p=1,all=TRUE)
# Robustness checks
rd.rob1 = rdrobust(data[,mort_related_pre],x,p=1,all=TRUE)
rd.rob2 = rdrobust(data[,mort_injury_post],x,p=1,all=TRUE)
View(rd.rob1)
rd.rob1.res   = cbind(rd.rob1$coef,rd.rob1$se,rd.rob1$ci)
rd.rob2.res   = cbind(rd.rob2$coef,rd.rob2$se,rd.rob2$ci)
xtable(rd.rob1.res,digits=c(0,2,2,2,2))
xtable(rd.rob2.res,digits=c(0,2,2,2,2))
install.packages('rdlocalrand')
install.packages('rdlocrand')
library(rdlocrand)
rdwinselect(x,data[,mort_related_pre])
rdwinselect(x,c(data[,mort_related_pre],data[,mort_injury_post])
rdwinselect(x,c(data[,mort_related_pre],data[,mort_injury_post]))
# Use defaults to compute recommended window for local randomization
rdwindow = rdwinselect(x,c(data[,mort_related_pre],data[,mort_injury_post]))
View(rdwindow)
rdwindow$window
rdrandinf(Y,x,wl=rdwindow$window[1],wr=rdwindow$window[2])
# Conduct randomization inference using recommended window
rd.rand.res = rdrandinf(Y,x,wl=rdwindow$window[1],wr=rdwindow$window[2])
View(rd.rand.res)
